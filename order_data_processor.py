"""
Ù…Ø¹Ø§Ù„Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
Order Data Processor for Large Datasets

ÙŠÙˆÙØ± Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ¹Ø§Ù„Ø© Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù…Ø¹:
- ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (chunks)
- ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø´Ø­Ù† ÙˆØ§Ù„Ù…Ù†Ø§Ø·Ù‚
- ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©
"""

import pandas as pd
import numpy as np
from datetime import datetime
import streamlit as st
from pathlib import Path
import pickle


class OrderDataProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    
    def __init__(self, file_path=None, dataframe=None, chunksize=10000):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
        
        Parameters:
        -----------
        file_path : str
            Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        dataframe : pd.DataFrame
            DataFrame Ø¬Ø§Ù‡Ø² (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        chunksize : int
            Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        self.file_path = file_path
        self.chunksize = chunksize
        
        if dataframe is not None:
            self.df = dataframe
        elif file_path is not None:
            self.df = self.load_data()
        else:
            self.df = None
    
    def load_data(self, sample_size=None):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙƒÙØ§Ø¡Ø©
        
        Parameters:
        -----------
        sample_size : int
            Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ù„Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© (None = ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
        
        Returns:
        --------
        pd.DataFrame
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©
        """
        try:
            if str(self.file_path).endswith('.csv'):
                # Ù…Ù„ÙØ§Øª Ø³Ù„Ø©: UTF-16 LE Ù…Ø¹ Tab separator
                # Ù…Ø­Ø§ÙˆÙ„Ø© UTF-16 Ø£ÙˆÙ„Ø§Ù‹ (Ù…Ù„ÙØ§Øª Ø³Ù„Ø© 2024-2025)
                try:
                    chunks = []
                    
                    for chunk in pd.read_csv(
                        self.file_path,
                        chunksize=self.chunksize,
                        encoding='utf-16',
                        sep='\t',  # Tab-separated ÙÙŠ Ù…Ù„ÙØ§Øª Ø³Ù„Ø©
                        low_memory=False
                    ):
                        # ØªÙ†Ø¸ÙŠÙ ÙƒÙ„ Ø¯ÙØ¹Ø©
                        chunk = self.clean_orders_data(chunk)
                        chunks.append(chunk)
                        
                        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø­Ø¯ Ù„Ù„Ø¹ÙŠÙ†Ø©
                        if sample_size and len(pd.concat(chunks, ignore_index=True)) >= sample_size:
                            break
                    
                    df = pd.concat(chunks, ignore_index=True)
                    
                    if sample_size:
                        df = df.sample(min(sample_size, len(df)))
                
                except (UnicodeDecodeError, pd.errors.ParserError):
                    # Ø¥Ø°Ø§ ÙØ´Ù„ UTF-16ØŒ Ø¬Ø±Ø¨ UTF-8 Ø§Ù„Ø¹Ø§Ø¯ÙŠ
                    try:
                        chunks = []
                        
                        for chunk in pd.read_csv(
                            self.file_path,
                            chunksize=self.chunksize,
                            encoding='utf-8',
                            low_memory=False
                        ):
                            chunk = self.clean_orders_data(chunk)
                            chunks.append(chunk)
                            
                            if sample_size and len(pd.concat(chunks, ignore_index=True)) >= sample_size:
                                break
                        
                        df = pd.concat(chunks, ignore_index=True)
                        
                        if sample_size:
                            df = df.sample(min(sample_size, len(df)))
                    
                    except Exception as e:
                        st.error(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}")
                        return pd.DataFrame()
                
            else:  # Excel
                df = pd.read_excel(self.file_path)
                df = self.clean_orders_data(df)
                
                if sample_size:
                    df = df.sample(min(sample_size, len(df)))
            
            return self.optimize_memory(df)
            
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return pd.DataFrame()
    
    def clean_orders_data(self, df):
        """
        ØªÙ†Ø¸ÙŠÙ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        
        Parameters:
        -----------
        df : pd.DataFrame
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…
        
        Returns:
        --------
        pd.DataFrame
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø¸ÙØ©
        """
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        date_columns = [col for col in df.columns if 'AT' in col.upper() or 'DATE' in col.upper()]
        for col in date_columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ================================
        # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø·Ù„Ø¨ (prep time)
        # ================================
        created_col = None
        packed_col = None
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®
        for col in df.columns:
            col_upper = col.upper()
            if 'CREATED' in col_upper and 'AT' in col_upper:
                created_col = col
            if 'PACKED' in col_upper and 'AT' in col_upper:
                packed_col = col
        
        if created_col and packed_col:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±Ù‚ Ø¨Ø§Ù„Ø¯Ù‚Ø§Ø¦Ù‚
            df['prep_time_minutes'] = (
                (df[packed_col] - df[created_col]).dt.total_seconds() / 60
            )
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© ÙˆØ§Ù„Ø´Ø§Ø°Ø©
            df.loc[df['prep_time_minutes'] < 0, 'prep_time_minutes'] = np.nan
            df.loc[df['prep_time_minutes'] > 1440, 'prep_time_minutes'] = np.nan  # Ø£ÙƒØ«Ø± Ù…Ù† ÙŠÙˆÙ…
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        if 'SHIPMENT WEIGHT' in df.columns:
            df['SHIPMENT WEIGHT'] = df['SHIPMENT WEIGHT'].astype(str).str.extract(r'(\d+\.?\d*)').astype(float)
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¨Ø§Ù„Øº
        amount_columns = [col for col in df.columns if any(x in col.upper() for x in ['AMOUNT', 'COST', 'FEE', 'PRICE'])]
        for col in amount_columns:
            if df[col].dtype == 'object':
                df[col] = df[col].astype(str).str.extract(r'(\d+\.?\d*)').astype(float)
        
        return df
    
    def optimize_memory(self, df):
        """
        ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        
        Parameters:
        -----------
        df : pd.DataFrame
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Returns:
        --------
        pd.DataFrame
            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        """
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„Ù€ category (ÙŠÙˆÙØ± 90% Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©)
        for col in df.select_dtypes(include=['object']).columns:
            num_unique = df[col].nunique()
            num_total = len(df[col])
            
            if num_unique / num_total < 0.5:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ø§Ù„ÙŠ
                df[col] = df[col].astype('category')
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµØ­ÙŠØ­Ø©
        for col in df.select_dtypes(include=['int']).columns:
            df[col] = pd.to_numeric(df[col], downcast='integer')
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø´Ø±ÙŠØ©
        for col in df.select_dtypes(include=['float']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')
        
        return df
    
    def analyze_prep_time(self):
        """
        ØªØ­Ù„ÙŠÙ„ ÙˆÙ‚Øª ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        
        Returns:
        --------
        dict
            ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„ÙˆÙ‚Øª Ø§Ù„ØªØ¬Ù‡ÙŠØ²
        """
        if self.df is None or 'prep_time_minutes' not in self.df.columns:
            return {
                'avg_prep_time': 0,
                'median_prep_time': 0,
                'min_prep_time': 0,
                'max_prep_time': 0,
                'by_customer': pd.DataFrame(),
                'distribution': {}
            }
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
        valid_data = self.df.dropna(subset=['prep_time_minutes'])
        
        if len(valid_data) == 0:
            return {
                'avg_prep_time': 0,
                'median_prep_time': 0,
                'min_prep_time': 0,
                'max_prep_time': 0,
                'by_customer': pd.DataFrame(),
                'distribution': {}
            }
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
        avg_prep = valid_data['prep_time_minutes'].mean()
        median_prep = valid_data['prep_time_minutes'].median()
        min_prep = valid_data['prep_time_minutes'].min()
        max_prep = valid_data['prep_time_minutes'].max()
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…ÙŠÙ„
        customer_col = None
        for col in valid_data.columns:
            if 'CUSTOMER' in col.upper() and 'PHONE' in col.upper():
                customer_col = col
                break
        
        by_customer = pd.DataFrame()
        if customer_col:
            by_customer = (
                valid_data.groupby(customer_col)['prep_time_minutes']
                .agg(['mean', 'count', 'min', 'max'])
                .reset_index()
            )
            by_customer.columns = ['customer', 'avg_prep_time', 'order_count', 'min_prep', 'max_prep']
            by_customer = by_customer.sort_values('avg_prep_time', ascending=False)
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£ÙˆÙ‚Ø§Øª
        distribution = {
            'very_fast': len(valid_data[valid_data['prep_time_minutes'] <= 30]),  # Ø£Ù‚Ù„ Ù…Ù† 30 Ø¯Ù‚ÙŠÙ‚Ø©
            'fast': len(valid_data[(valid_data['prep_time_minutes'] > 30) & (valid_data['prep_time_minutes'] <= 60)]),  # 30-60 Ø¯Ù‚ÙŠÙ‚Ø©
            'normal': len(valid_data[(valid_data['prep_time_minutes'] > 60) & (valid_data['prep_time_minutes'] <= 120)]),  # 1-2 Ø³Ø§Ø¹Ø©
            'slow': len(valid_data[(valid_data['prep_time_minutes'] > 120) & (valid_data['prep_time_minutes'] <= 240)]),  # 2-4 Ø³Ø§Ø¹Ø§Øª
            'very_slow': len(valid_data[valid_data['prep_time_minutes'] > 240])  # Ø£ÙƒØ«Ø± Ù…Ù† 4 Ø³Ø§Ø¹Ø§Øª
        }
        
        return {
            'avg_prep_time': avg_prep,
            'median_prep_time': median_prep,
            'min_prep_time': min_prep,
            'max_prep_time': max_prep,
            'by_customer': by_customer,
            'distribution': distribution,
            'total_orders': len(valid_data)
        }


class PricingOptimizer:
    """Ù…Ø­Ø³Ù‘Ù† Ø§Ù„ØªØ³Ø¹ÙŠØ± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
    
    def __init__(self, orders_data):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        
        Parameters:
        -----------
        orders_data : pd.DataFrame
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        """
        self.orders = orders_data
        self.shipping_analysis = self.analyze_shipping_costs()
        self.regional_analysis = self.analyze_regional_patterns()
        self.partner_performance = self.analyze_partner_performance()
    
    def analyze_shipping_costs(self):
        """ØªØ­Ù„ÙŠÙ„ ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø´Ø­Ù† Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
            available_cols = self.orders.columns.tolist()
            
            # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù…Ø±Ù†Ø©)
            city_col = next((col for col in available_cols if 'DESTINATION' in col.upper() and 'CITY' in col.upper()), None)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªÙƒÙ„ÙØ©
            cost_col = None
            for col in ['SHIPPING COST', 'COD FEE', 'DELIVERY FEE', 'SHIPPING FEE']:
                if col in available_cols:
                    cost_col = col
                    break
            
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ØªÙƒÙ„ÙØ©ØŒ Ù†Ø³ØªØ®Ø¯Ù… ORDER AMOUNT ÙƒÙ…Ù‚ÙŠØ§Ø³ Ø¨Ø¯ÙŠÙ„
            if not cost_col and 'ORDER AMOUNT' in available_cols:
                st.info("ğŸ’¡ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ ØªÙƒÙ„ÙØ© Ø§Ù„Ø´Ø­Ù†ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… ORDER AMOUNT")
                cost_col = 'ORDER AMOUNT'
            
            if not city_col or not cost_col:
                st.warning("âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ DESTINATION CITY Ùˆ SHIPPING COST")
                return pd.DataFrame()
            
            agg_dict = {
                cost_col: 'mean',
                'ORDER ID': 'count'
            }
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯Øª
            if 'SHIPMENT WEIGHT' in available_cols:
                agg_dict['SHIPMENT WEIGHT'] = 'mean'
            if 'ORDER AMOUNT' in available_cols and cost_col != 'ORDER AMOUNT':
                agg_dict['ORDER AMOUNT'] = 'mean'
            if 'COD FEE' in available_cols:
                agg_dict['COD FEE'] = 'mean'
            
            group_cols = [city_col]
            if 'SHIPPING PARTNER' in available_cols:
                group_cols.append('SHIPPING PARTNER')
            elif 'COURIER PARTNER' in available_cols:
                group_cols.append('COURIER PARTNER')
            
            shipping_data = self.orders.groupby(group_cols).agg(agg_dict).reset_index()
            shipping_data.columns = [col if isinstance(col, str) else col[0] for col in shipping_data.columns]
            
            return shipping_data
            
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø­Ù†: {str(e)}")
            return pd.DataFrame()
    
    def analyze_regional_patterns(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
            city_col = next((col for col in self.orders.columns 
                           if 'DESTINATION' in col.upper() and 'CITY' in col.upper()), None)
            
            if not city_col:
                st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ DESTINATION CITY")
                return pd.DataFrame()
            
            agg_dict = {'ORDER ID': 'count'}
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
            if 'ORDER AMOUNT' in self.orders.columns:
                agg_dict['ORDER AMOUNT'] = ['mean', 'median', 'sum']
            if 'SHIPPING COST' in self.orders.columns:
                agg_dict['SHIPPING COST'] = 'mean'
            if 'COD FEE' in self.orders.columns:
                agg_dict['COD FEE'] = ['mean', 'sum']
            if 'SHIPMENT WEIGHT' in self.orders.columns:
                agg_dict['SHIPMENT WEIGHT'] = 'mean'
            
            regional_stats = self.orders.groupby(city_col).agg(agg_dict)
            regional_stats.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col 
                                     for col in regional_stats.columns.values]
            
            return regional_stats.reset_index()
            
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ù‚Ù„ÙŠÙ…ÙŠ: {str(e)}")
            return pd.DataFrame()
    
    def analyze_partner_performance(self):
        """ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø´Ø±ÙƒØ§Ø¡ Ø§Ù„Ø´Ø­Ù†"""
        try:
            if 'SHIPPING PARTNER' not in self.orders.columns:
                return pd.DataFrame()
            
            partner_stats = self.orders.groupby('SHIPPING PARTNER').agg({
                'ORDER ID': 'count',
                'SHIPPING COST': 'mean'
            }).reset_index()
            
            partner_stats.columns = ['Partner', 'Order_Count', 'Avg_Cost']
            partner_stats['Performance_Score'] = (
                partner_stats['Order_Count'] / partner_stats['Avg_Cost']
            )
            
            return partner_stats.sort_values('Performance_Score', ascending=False)
            
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø±ÙƒØ§Ø¡: {str(e)}")
            return pd.DataFrame()
    
    def calculate_optimal_shipping_price(self, city, weight, order_value, payment_method='PREPAID'):
        """
        Ø­Ø³Ø§Ø¨ Ø³Ø¹Ø± Ø§Ù„Ø´Ø­Ù† Ø§Ù„Ø£Ù…Ø«Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        
        Parameters:
        -----------
        city : str
            Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
        weight : float
            Ø§Ù„ÙˆØ²Ù†
        order_value : float
            Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨
        payment_method : str
            Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¯ÙØ¹
        
        Returns:
        --------
        float
            Ø³Ø¹Ø± Ø§Ù„Ø´Ø­Ù† Ø§Ù„Ù…Ø­Ø³ÙˆØ¨
        """
        if self.shipping_analysis.empty:
            # Ø³Ø¹Ø± Ø§ÙØªØ±Ø§Ø¶ÙŠ
            return 25.0
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø­Ù† Ù„Ù„Ù…Ø¯ÙŠÙ†Ø©
        city_data = self.shipping_analysis[
            self.shipping_analysis['DESTINATION CITY'] == city
        ]
        
        if len(city_data) > 0:
            avg_shipping_cost = city_data['SHIPPING COST'].mean()
            avg_weight = city_data.get('SHIPMENT WEIGHT', pd.Series([1.0])).mean()
        else:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…
            avg_shipping_cost = self.shipping_analysis['SHIPPING COST'].mean()
            avg_weight = self.shipping_analysis.get('SHIPMENT WEIGHT', pd.Series([1.0])).mean()
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„ÙˆØ²Ù†
        weight_factor = max(0.5, min(2.0, weight / max(avg_weight, 0.5)))
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨ (Ø®ØµÙ… Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)
        order_value_factor = 1.0
        if order_value > 500:
            order_value_factor = 0.8
        elif order_value > 200:
            order_value_factor = 0.9
        
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¯ÙØ¹
        payment_factor = 0.9 if payment_method == 'PREPAID' else 1.1
        
        # Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ + Ù‡Ø§Ù…Ø´ Ø±Ø¨Ø­
        base_price = avg_shipping_cost * weight_factor
        profit_margin = 0.25  # 25% Ù‡Ø§Ù…Ø´ Ø±Ø¨Ø­
        
        final_price = base_price * order_value_factor * payment_factor * (1 + profit_margin)
        
        return round(final_price, 2)
    
    def recommend_shipping_partner(self, city, weight=None, urgency='normal'):
        """
        ØªÙˆØµÙŠØ© Ø´Ø±ÙŠÙƒ Ø´Ø­Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
        
        Parameters:
        -----------
        city : str
            Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©
        weight : float
            Ø§Ù„ÙˆØ²Ù† (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        urgency : str
            Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø§Ø³ØªØ¹Ø¬Ø§Ù„
        
        Returns:
        --------
        str
            Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙŠÙƒ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡
        """
        if self.shipping_analysis.empty or 'SHIPPING PARTNER' not in self.shipping_analysis.columns:
            return "Ø§Ù„Ø´Ø±ÙŠÙƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ"
        
        city_partners = self.shipping_analysis[
            self.shipping_analysis['DESTINATION CITY'] == city
        ]
        
        if len(city_partners) > 0:
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø´Ø±ÙƒØ§Ø¡ Ø­Ø³Ø¨ Ø§Ù„ØªÙƒÙ„ÙØ© ÙˆØ§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©
            city_partners = city_partners.copy()
            city_partners['score'] = (
                city_partners['SHIPPING COST'] * 0.6 +
                (1 / city_partners['ORDER ID'].clip(lower=1)) * 0.4
            )
            
            best_partner = city_partners.loc[city_partners['score'].idxmin()]
            return best_partner['SHIPPING PARTNER']
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø´Ø±ÙŠÙƒ Ø§Ù„Ø£ÙØ¶Ù„ Ø¹Ù…ÙˆÙ…Ø§Ù‹
        if not self.partner_performance.empty:
            return self.partner_performance.iloc[0]['Partner']
        
        return "Ø§Ù„Ø´Ø±ÙŠÙƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ"
    
    def calculate_additional_costs(self, weight, payment_method, order_value=0):
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        
        Parameters:
        -----------
        weight : float
            Ø§Ù„ÙˆØ²Ù†
        payment_method : str
            Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¯ÙØ¹
        order_value : float
            Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨
        
        Returns:
        --------
        dict
            Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙØµÙ„Ø©
        """
        # Ø±Ø³ÙˆÙ… Ø§Ù„Ø¯ÙØ¹ Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù…
        cod_fee = 16.52 if payment_method == 'POSTPAID' else 0
        
        # Ø±Ø³ÙˆÙ… Ø§Ù„ØªØºÙ„ÙŠÙ (Ø­Ø³Ø¨ Ø§Ù„ÙˆØ²Ù†)
        packaging_fee = max(5, weight * 2)
        
        # Ø±Ø³ÙˆÙ… Ø§Ù„Ù…Ù†Ø§ÙˆÙ„Ø©
        handling_fee = 3.0
        
        # Ø±Ø³ÙˆÙ… Ø§Ù„ØªØ£Ù…ÙŠÙ† (Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)
        insurance_fee = order_value * 0.01 if order_value > 1000 else 0
        
        return {
            'cod_fee': round(cod_fee, 2),
            'packaging_fee': round(packaging_fee, 2),
            'handling_fee': round(handling_fee, 2),
            'insurance_fee': round(insurance_fee, 2),
            'total_additional': round(cod_fee + packaging_fee + handling_fee + insurance_fee, 2)
        }
    
    def save_cache(self, cache_file='pricing_cache.pkl'):
        """Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ù„Ù„ØªØ³Ø±ÙŠØ¹"""
        try:
            cache_data = {
                'shipping_analysis': self.shipping_analysis,
                'regional_analysis': self.regional_analysis,
                'partner_performance': self.partner_performance
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            return True
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ÙƒØ§Ø´: {str(e)}")
            return False
    
    @staticmethod
    def load_cache(cache_file='pricing_cache.pkl'):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            st.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ø´: {str(e)}")
            return None


def get_memory_usage(df):
    """Ø­Ø³Ø§Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù€ DataFrame"""
    memory_bytes = df.memory_usage(deep=True).sum()
    memory_mb = memory_bytes / (1024 ** 2)
    return f"{memory_mb:.2f} MB"


def get_data_summary(df):
    """Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    summary = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'memory_usage': get_memory_usage(df),
        'date_range': None,
        'missing_values': df.isnull().sum().sum(),
        'duplicate_rows': df.duplicated().sum()
    }
    
    # Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
    date_cols = df.select_dtypes(include=['datetime64']).columns
    if len(date_cols) > 0:
        first_date = df[date_cols[0]].min()
        last_date = df[date_cols[0]].max()
        summary['date_range'] = f"{first_date.date()} Ø¥Ù„Ù‰ {last_date.date()}"
    
    return summary
